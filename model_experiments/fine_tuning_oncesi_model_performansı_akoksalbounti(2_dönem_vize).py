# -*- coding: utf-8 -*-
"""Fine_tuning_oncesi_model_performansı_akoksalbounti(2.dönem_vize).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d0wjoGwLuzhj52MO3zUi9YK9yBm3vsUI
"""

!pip install transformers datasets scikit-learn torch

import pandas as pd
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# 📂 CSV Dosyasını Yükle (Test Verisi)
# Burada kendi CSV dosyanı yüklemen gerekiyor. CSV dosyasında 'text' ve 'sentiment' sütunları olmalı.
# 'text' sütunundaki metinler model tarafından analiz edilecek, 'sentiment' ise gerçek duygu etiketlerini içeriyor.
df = pd.read_csv("/content/drive/MyDrive/random_50_labeled_tweets.csv")

# Birkaç satırı kontrol edelim
print(df.head())

# Eğer 'text' ve 'label' sütunlarındaki isimler farklıysa, ona göre düzenle.
# Örneğin, 'text' yerine 'review' veya 'sentence' gibi bir isim olabilir.
# df['text'] ve df['label'] olarak güncelle.

#Model ve tokenizer yükleme
model_name = "akoksal/bounti" # Bounti modelini kullanıyoruz
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

print(model.config)

# 💬 Sentiment Analysis Pipeline oluşturma
nlp_pipeline = pipeline("text-classification", model=model, tokenizer=tokenizer)

# 🧪 Test Veri Setini Modelle Test Et
# Bu adımda, modelin 'text' sütunundaki her metni analiz etmesini sağlıyoruz.
# Modelin verdiği tahminler 'predicted_label' sütununa yazılacak.
# text → Metinleri içerir. (Önceden var)
# label → Gerçek etiketler. (Önceden var)
# predicted_label → Modelin tahmin ettiği etiketler. (Yeni eklenen sütun)

# 🧪 3️⃣ Test Veri Setini Modelle Test Et
# Model 'text' sütunundaki her metni analiz edecek
df["predicted_label"] = df["text"].apply(lambda x: nlp_pipeline(x)[0]["label"])

# 🔄 4️⃣ İngilizce → Türkçe Etiket Çevirisi
label_mapping = {
    "positive": "pozitif",
    "negative": "negatif",
    "neutral": "nötr"
}
df["predicted_label"] = df["predicted_label"].map(label_mapping)

# 🔍 5️⃣ Gerçek ve Tahmin Etiketlerini Kontrol Et
print(df.head())  # İlk 5 satırı yazdırarak her şeyin doğru çalıştığını gör

# 📊 6️⃣ Metrikleri Hesapla
true_labels = df["sentiment"]
predicted_labels = df["predicted_label"]

accuracy = accuracy_score(true_labels, predicted_labels)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='macro', zero_division=1)

# 📝 7️⃣ Sonuçları Yazdır
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

# 💾 8️⃣ Sonuçları Yeni Bir CSV Dosyasına Kaydet
df.to_csv("test_sonuclari.csv", index=False)

import pandas as pd
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 📂 1️⃣ CSV Dosyasını Yükle
df = pd.read_csv("/content/drive/MyDrive/random_50_labeled_tweets.csv")

print("\n🔍 Veri setindeki ilk 5 satır:")
print(df[["text", "sentiment"]].head())

# 🧾 2️⃣ Veri Seti Etiketlerini Kontrol Et
print("\n📊 Veri setindeki benzersiz GERÇEK etiketler:")
print(df["sentiment"].value_counts())
print("Benzersiz değerler:", df["sentiment"].unique())

# 🔧 3️⃣ Model ve tokenizer yükleme
model_name = "akoksal/bounti"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
print("\n📌 Modelin config’inden id2label:")
print(model.config.id2label)

# 💬 4️⃣ Sentiment Analysis Pipeline
nlp_pipeline = pipeline("text-classification", model=model, tokenizer=tokenizer)

# 🔍 5️⃣ Tahminleri Al
df["predicted_raw"] = df["text"].apply(lambda x: nlp_pipeline(x)[0]["label"])

# 🧭 6️⃣ Tahmin Etiketlerini (English → Türkçe) Map Et
label_mapping = {
    "positive": "pozitif",
    "negative": "negatif",
    "neutral": "nötr"
}

df["predicted_label"] = df["predicted_raw"].map(label_mapping)

# ❗ 7️⃣ Eğer map başarısızsa (None dönerse) uyarı ver
nan_count = df["predicted_label"].isna().sum()
if nan_count > 0:
    print(f"\n❗ UYARI: {nan_count} tahmin eşleşmedi. Tahmin değerleri şunlardı:")
    print(df["predicted_raw"].value_counts())
    print("Map işlemi sonrası oluşan eşsiz predicted_label değerleri:", df["predicted_label"].unique())

# 🔍 8️⃣ Etiket Karşılaştırması
print("\n✅ Etiket Karşılaştırması:")
print("Gerçek Etiketler:")
print(df["sentiment"].value_counts())
print("\nModel Tahmin Etiketleri:")
print(df["predicted_label"].value_counts())

# 🔁 Gerçek etiketleri küçük harfe çevir (uyumluluk için)
df["sentiment"] = df["sentiment"].str.lower()


# 📐 9️⃣ Metrik Hesaplama
true_labels = df["sentiment"]
predicted_labels = df["predicted_label"]



accuracy = accuracy_score(true_labels, predicted_labels)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='macro', zero_division=1)

print("\n📊 Model Performansı:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision (macro): {precision:.4f}")
print(f"Recall (macro): {recall:.4f}")
print(f"F1 Score (macro): {f1:.4f}")

# 🧯 10️⃣ Yanlış Tahmin Edilen Örnekler
wrong_df = df[df["sentiment"] != df["predicted_label"]]
print(f"\n❌ Yanlış tahmin edilen örnek sayısı: {len(wrong_df)}")
print("🔍 Yanlış tahmin örneklerinden bazıları:")
print(wrong_df[["text", "sentiment", "predicted_label"]].head())

# 🧮 11️⃣ Confusion Matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=["pozitif", "negatif", "nötr"])
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=["pozitif", "negatif", "nötr"],
            yticklabels=["pozitif", "negatif", "nötr"])
plt.xlabel("Tahmin")
plt.ylabel("Gerçek")
plt.title("Confusion Matrix - Bounti Modeli")
plt.show()

# 💾 12️⃣ Kaydetme
df.to_csv("bounti_model_test_sonuclari.csv", index=False)